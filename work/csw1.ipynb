{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1 : Movie Recommendation from Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents from file and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 42204 \n"
     ]
    }
   ],
   "source": [
    "movies_meta=pd.read_csv(\"data/movie.metadata.tsv\", \n",
    "                         sep='\\t', header=None, usecols=[0,1,2,3,8], \n",
    "                         names=['wID', 'fID', 'title', 'data', 'genres' ])\n",
    "\n",
    "movies_plot=pd.read_csv(\"data/plot_summaries.txt\", \n",
    "                         sep='\\t', header=None, usecols=[0,1], \n",
    "                         names=['wID', 'plot'])\n",
    "\n",
    "movies_merged = pd.merge(movies_meta, movies_plot, on='wID', how='inner')\n",
    "    \n",
    "print(\"Retrieved {} \".format(len(movies_merged)))\n",
    "\n",
    "with open(\"data/vocabulary.pk\",\"rb\") as pickle_in:\n",
    "    vocabulary = pickle.load(pickle_in)\n",
    "\n",
    "with open(\"data/tf_idf_small.pk\",\"rb\") as pickle_in:\n",
    "    tf_idf = pickle.load(pickle_in)\n",
    "    \n",
    "# print stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to Compute similarity between target and other docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(target_row):  \n",
    "  tfidf =  tf_idf[target_row['wID']]\n",
    "  num_words = 20\n",
    "  sorted_tfidf = [\n",
    "    w  for (w, _) in sorted(tfidf.items(), key=lambda kv: kv[1], reverse=True)\n",
    "  ]\n",
    "  print(target_row['title'])\n",
    "  print(\"Higher TF-IDF: {}\".format(sorted_tfidf[:num_words]))\n",
    "\n",
    "\n",
    "def cosine_dic(dic1,dic2):\n",
    "    numerator = 0\n",
    "    dena = 0\n",
    "    for key1,val1 in dic1.items():\n",
    "        numerator += val1*dic2.get(key1,0.0)\n",
    "        dena += val1*val1\n",
    "    denb = 0\n",
    "    for val2 in dic2.values():\n",
    "        denb += val2*val2\n",
    "    return numerator/math.sqrt(dena*denb)    \n",
    "    \n",
    "def similar(target_1, target_2):\n",
    "    tfidf1 = tf_idf[target_1['wID']]\n",
    "    tfidf2 = tf_idf[target_2['wID']]\n",
    "    return cosine_dic(tfidf1, tfidf2)\n",
    "    \n",
    "    \n",
    "def rocchio(pos, neg):\n",
    "    alpha = 0.65\n",
    "    a = {}\n",
    "    for t in pos:\n",
    "        tf = tf_idf[t['wID']]\n",
    "        num_w = len(tf)\n",
    "        a.update({ k: (a.get(k, 0.0) + v/num_w) for k,v in tf.items() })\n",
    "    b = {}    \n",
    "    for t in neg:\n",
    "        tf = tf_idf[t['wID']]\n",
    "        num_w = len(tf)\n",
    "        b.update({ k: (b.get(k, 0.0) + v/num_w) for k,v in tf.items() })\n",
    "        \n",
    "    c_pos = a.copy()\n",
    "    c_pos.update({ k: (a.get(k, 0.0)*alpha - b.get(k, 0.0)*(1-alpha)) for k,v in b.items() })\n",
    "\n",
    "    c_neg = b.copy()\n",
    "    c_neg.update({ k: (b.get(k, 0.0)*alpha - a.get(k, 0.0)*(1-alpha)) for k,v in a.items() })\n",
    "    return c_pos, c_neg\n",
    "    \n",
    "def is_relevant(target, c_pos, c_neg):\n",
    "    beta = 1.5\n",
    "    tfidf = tf_idf[target['wID']]    \n",
    "    if cosine_dic(tfidf, c_pos) > cosine_dic(tfidf, c_neg)*beta:\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example based search\n",
    "\n",
    "1. Identify a set of relevant movies\n",
    "2. Identify a set of unwanted movies\n",
    "3. Use 5 of each as negative/positive examples\n",
    "4. Test on entire movie dataset, see if we can retrieve our good examples and avoid the bad ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with higher TF-IDF in the positive vector\n",
      "['ballard', 'martian', 'caesar', 'shang', 'armando', 'obi', 'carter', 'ape', 'burroughs', 'medallion', 'jericho', 'wan', 'leia', 'ripley', 'miner', 'luke', 'helium', 'vader', 'kenobi', 'williams']\n",
      "Words with higher TF-IDF in the negative vector\n",
      "['andy', 'tarzan', 'buzz', 'woody', 'marlin', 'gorilla', 'nemo', 'clayton', 'dory', 'kala', 'rc', 'nigel', 'porter', 'anna', 'sid', 'jane', 'toy', 'miranda', 'treehouse', 'explorer']\n",
      "Simple Naive Check of the Classifier Performance\n",
      "Right! Ghosts of Mars\n",
      "Right! Prometheus\n",
      "Right! AVP: Alien vs. Predator\n",
      "Right! Conquest of the Planet of the Apes\n",
      "Right! Planet of the Apes\n",
      "Right! 2001: A Space Odyssey\n",
      "Right! Rise of the Planet of the Apes\n",
      "Wrong! Indiana Jones and the Last Crusade\n",
      "Right! John Carter\n",
      "Right! Alien\n",
      "Right! Planet of the Apes\n",
      "Wrong! Space Jam\n",
      "Right! Star Wars Episode IV: A New Hope\n",
      "11 2\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "t_examples_pos = ['Ghosts of Mars',\n",
    "'Conquest of the Planet of the Apes',\n",
    "'John Carter',\n",
    "'Alien',\n",
    "'Star Wars Episode IV: A New Hope',                  \n",
    "'2001: A Space Odyssey',\n",
    "'Prometheus',\n",
    "'Planet of the Apes',\n",
    "'Rise of the Planet of the Apes',\n",
    "'AVP: Alien vs. Predator']\n",
    "\n",
    "t_examples_neg =['Toy Story',\n",
    "'Notting Hill',\n",
    "'Finding Nemo',\n",
    "'Tarzan',\n",
    "'The Devil Wears Prada',\n",
    "'Space Jam',\n",
    "\"Bridget Jones's Diary\",\n",
    "'Indiana Jones and the Last Crusade',\n",
    "'King Kong',\n",
    "'The Lion King',\n",
    "'Robin Hood: Men in Tights']\n",
    "\n",
    "ex_pos = []\n",
    "for t in t_examples_pos[:5]:\n",
    "#    print(t)\n",
    "    target = movies_merged.loc[movies_merged['title'] == t].iloc[0]\n",
    "    ex_pos.append(target)\n",
    "\n",
    "ex_neg = []\n",
    "for t in t_examples_neg[:5]:\n",
    "#    print(t)    \n",
    "    target = movies_merged.loc[movies_merged['title'] == t].iloc[0]\n",
    "    ex_neg.append(target)\n",
    "   \n",
    "c_pos, c_neg = rocchio(ex_pos, ex_neg)\n",
    "\n",
    "countp = 0\n",
    "\n",
    "print(\"Words with higher TF-IDF in the positive vector\")\n",
    "sorted_tfidf = [\n",
    "w  for (w, _) in sorted(c_pos.items(), key=lambda kv: kv[1], reverse=True)\n",
    "]\n",
    "print(sorted_tfidf[:20])\n",
    "\n",
    "print(\"Words with higher TF-IDF in the negative vector\")\n",
    "sorted_tfidf = [\n",
    "w  for (w, _) in sorted(c_neg.items(), key=lambda kv: kv[1], reverse=True)\n",
    "]\n",
    "print(sorted_tfidf[:20])\n",
    "\n",
    "\n",
    "print(\"Simple Naive Check of the Classifier Performance\")\n",
    "rightc=0\n",
    "wrongc=0\n",
    "for idx, movie in movies_merged.iterrows():\n",
    "    #scr = similar(target_1, movie)\n",
    "    if is_relevant(movie,c_pos, c_neg) and (movie['title'] in t_examples_pos):\n",
    "        print(\"Right! {}\".format(movie['title'])) \n",
    "        rightc+=1\n",
    "    if is_relevant(movie,c_pos, c_neg) and (movie['title'] in t_examples_neg):\n",
    "        print(\"Wrong! {}\".format(movie['title'])) \n",
    "        wrongc+=1\n",
    "print(rightc,wrongc)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
